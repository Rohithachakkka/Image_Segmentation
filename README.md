# Image_Segmentation

This project focuses on semantic image segmentation using deep learning, where the goal is to classify each pixel in an image into a categoryâ€”in this case, distinguishing between pet and background regions. We utilize the Oxford-IIIT Pet dataset, which provides high-quality images of 37 breeds of cats and dogs, along with their corresponding pixel-level segmentation masks. Image segmentation is a crucial task in computer vision, especially for applications such as medical imaging, autonomous vehicles, and object detection. By training a model on labeled datasets like this one, we can teach machines to understand the structure of an image at a fine-grained level.
In this code, the images and their segmentation masks are preprocessed by resizing and normalizing them to ensure consistency and improve model performance. The masks are adjusted so that the model can easily differentiate between the pet and the background. This preprocessed data can then be used to train a neural network to learn the underlying features necessary for pixel-wise classification. To verify the data preprocessing pipeline, a sample image and its corresponding mask are visualized. This helps ensure that the inputs to the model are correctly formatted and aligned.
The main objective of this project is to demonstrate how TensorFlow and TensorFlow Datasets can be effectively used for preparing and visualizing data for image segmentation tasks, serving as a foundation for building more complex models such as U-Net or DeepLab.

